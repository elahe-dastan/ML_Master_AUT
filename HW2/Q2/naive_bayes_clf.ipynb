{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions with Naive Bayes On The Wine Dataset\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "from math import pi\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class GNB:\n",
    "    def __init__(self):\n",
    "        self.summaries = dict()\n",
    "        self.prior_probabilities = dict()\n",
    "\n",
    "    # Split the dataset by class values, returns a dictionary\n",
    "    def separate_by_class(self, x, y):\n",
    "        separated = dict()\n",
    "        for class_value in pd.unique(y):\n",
    "            separated[class_value] = x[y == class_value]\n",
    "            \n",
    "        return separated\n",
    " \n",
    "    # Split dataset by class then calculate statistics for each row\n",
    "    def train(self, x, y):\n",
    "        separated = self.separate_by_class(x, y)\n",
    "        for class_value, rows in separated.items():\n",
    "            self.prior_probabilities[class_value] = \n",
    "            print(len(rows))\n",
    "            print(len(x))\n",
    "            self.summaries[class_value] = [rows.mean(), rows.std()]\n",
    " \n",
    "    # Calculate the Gaussian probability distribution function for x\n",
    "    def calculate_probability(self, x, mean, stdev):\n",
    "        exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "        \n",
    "        return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    " \n",
    "    # Calculate the probabilities of predicting each class for a given row\n",
    "    def calculate_class_probabilities(self, row):\n",
    "        total_rows = sum([self.summaries[label][0][2] for label in self.summaries])\n",
    "        probabilities = dict()\n",
    "        for class_value, class_summaries in summaries.items():\n",
    "            probabilities[class_value] = self.summaries[class_value][0][2]/float(total_rows)\n",
    "            for i in range(len(class_summaries)):\n",
    "                mean, stdev, _ = class_summaries[i]\n",
    "                probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "        return probabilities\n",
    " \n",
    "    # Predict the class for a given row\n",
    "    def predict(self, row):\n",
    "        probabilities = self.calculate_class_probabilities(row)\n",
    "        best_label, best_prob = None, -1\n",
    "        for class_value, probability in probabilities.items():\n",
    "            if best_label is None or probability > best_prob:\n",
    "                best_prob = probability\n",
    "                best_label = class_value\n",
    "        return best_label\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "142\n",
      "38\n",
      "142\n",
      "57\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with Naive Bayes on Iris Dataset\n",
    "filename = 'data/wine.data'\n",
    "dataset = pd.read_csv(filename, header=None)\n",
    "y = dataset[0]\n",
    "X = dataset.drop(columns=[0])\n",
    "X, X_test, y, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "\n",
    "# fit model\n",
    "gnb_clf = GNB()\n",
    "gnb_clf.train(X, y)\n",
    "\n",
    "# predict the label\n",
    "label = model.predict(row)\n",
    "# print('Data=%s, Predicted: %s' % (row, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
