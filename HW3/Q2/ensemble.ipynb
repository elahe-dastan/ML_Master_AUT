{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"p2_data/data_train.csv\", header=None)\n",
    "target = train.shape[1]-1\n",
    "y = train[target].to_numpy()\n",
    "X = train.drop(columns=[target]).to_numpy()\n",
    "\n",
    "test = pd.read_csv(\"p2_data/data_test.csv\", header=None)\n",
    "y_test = test[target]\n",
    "X_test = test.drop(columns=[target])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A)<br/>\n",
    "Implement Random Forest:\n",
    "1. It gets the number of trees (n) and their height\n",
    "2. Samples the dataset with replacement(bootstrap) n times\n",
    "3. For each tree randomly selects a few features\n",
    "4. Train all trees\n",
    "5. sum the predictions of all trees and use argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import random\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n, depth):\n",
    "        self.n = n\n",
    "        self.depth = depth\n",
    "        self.trees = []\n",
    "        self.features = []\n",
    "        self.samplesX = []\n",
    "        self.samplesy = []\n",
    "        self.n_classes = 2\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        for i in range(self.n):\n",
    "            clf = tree.DecisionTreeClassifier(max_depth=self.depth)\n",
    "            self.trees.append(clf)\n",
    "            \n",
    "    def fit(self, X, y, n):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        for i in range(self.n):\n",
    "            self.bootstrap(X, y)\n",
    "            self.random_features(n, X.shape[1]-1)\n",
    "            self.trees[i] = self.trees[i].fit(self.samplesX[i][:, self.features[i]], self.samplesy[i])\n",
    "            \n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(shape=(len(X), self.n_classes))\n",
    "        for i in range(self.n):\n",
    "            predictions = np.add(predictions,self.trees[i].predict_proba(X[:, self.features[i]]))\n",
    "            \n",
    "        return np.argmax(predictions, axis=1)\n",
    "\n",
    "    def bootstrap(self, X, y):\n",
    "        r = random.randint(0, 1000)\n",
    "        bootX = resample(X, replace=True, n_samples=len(X), random_state=r)\n",
    "        booty = resample(y, replace=True, n_samples=len(X), random_state=r)\n",
    "        self.samplesX.append(bootX)\n",
    "        self.samplesy.append(booty)\n",
    "        \n",
    "    def random_features(self, n, n_features):\n",
    "        features = []\n",
    "        for i in range(n):\n",
    "            features.append(random.randint(0, n_features))\n",
    "        self.features.append(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForest(15, 3)\n",
    "clf.fit(X, y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 1 ... 5 1 7]\n",
      "[8 2 1 ... 3 2 7]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "predictions = clf.predict(X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8155858019749133"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[742,   6,   0,   0,   4,   0,  11,   0,  17,   0],\n",
       "       [  0, 542, 160,  55,  12,   0,   4,   0,   0,   6],\n",
       "       [  0,   8, 753,   1,   1,   0,   3,  13,   1,   0],\n",
       "       [  0,  15,   1, 697,   1,   0,   0,   0,   0,   5],\n",
       "       [  1,   2,   0,   1, 751,   1,  20,   0,   0,   4],\n",
       "       [  1,   0,   0, 179,   1, 456,   4,   0,   2,  77],\n",
       "       [  0,   0,   2,   3,   2,   1, 703,   9,   0,   0],\n",
       "       [  0,  90,   4,   5,   1,   1,   7, 658,  11,   1],\n",
       "       [129,  12,   6,  11,   5,   4,  10, 108, 379,  55],\n",
       "       [  1,  74,   0,  87,  20,   2,   0,   0,   2, 533]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B)<br/>\n",
    "Implement AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import random\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.trees = [] \n",
    "        self.alphas = []\n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        for i in range(self.n):\n",
    "            stump = tree.DecisionTreeClassifier(max_depth=1)\n",
    "            self.trees.append(stump)\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        n_samples, _ = X.shape\n",
    "        \n",
    "        # init weight\n",
    "        w = np.full(n_samples, (1/n_samples))\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            self.trees[i] = self.trees[i].fit(X, y, sample_weight=w)\n",
    "            predictions = self.trees[i].predict(X)\n",
    "\n",
    "#             print(predictions)\n",
    "            \n",
    "            missclassified = w[y != predictions]\n",
    "            error = sum(missclassified)\n",
    "            \n",
    "            print(np.sum(w))\n",
    "            print(missclassified.shape)\n",
    "            print(np.sum(missclassified))\n",
    "            print(\"++++++++++++\")\n",
    "            \n",
    "            EPS = 1e-10\n",
    "            alpha = 0.5 * np.log((1-error) / (error+EPS))\n",
    "            self.alphas.append(alpha)\n",
    "           \n",
    "            w *= np.exp(-alpha * y * predictions)\n",
    "            w /= np.sum(w)\n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        predictions = np.array([])\n",
    "        for i in range(self.n):\n",
    "            np.append(predictions, self.alphas[i] * self.trees[i].predict_proba(X))\n",
    "        print(predictions)\n",
    "        \n",
    "        y_pred = np.sum(predictions, axis=0)\n",
    "        return np.sign(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n",
      "(5944,)\n",
      "0.7931678676274352\n",
      "++++++++++++\n",
      "0.9999999999999998\n",
      "(6106,)\n",
      "0.09773139668897887\n",
      "++++++++++++\n",
      "0.9999999999999998\n",
      "(5988,)\n",
      "1.1837401444314504e-05\n",
      "++++++++++++\n",
      "1.0\n",
      "(6694,)\n",
      "8.572617596505707e-06\n",
      "++++++++++++\n",
      "1.0\n",
      "(5988,)\n",
      "8.029670221883996e-06\n",
      "++++++++++++\n",
      "1.0\n",
      "(6714,)\n",
      "8.03124432881917e-06\n",
      "++++++++++++\n",
      "1.0\n",
      "(6714,)\n",
      "8.03124432881917e-06\n",
      "++++++++++++\n",
      "1.0\n",
      "(6714,)\n",
      "8.03124432881917e-06\n",
      "++++++++++++\n",
      "1.0\n",
      "(6714,)\n",
      "8.03124432881917e-06\n",
      "++++++++++++\n",
      "1.0\n",
      "(6714,)\n",
      "8.03124432881917e-06\n",
      "++++++++++++\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoost(10)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# print(y)\n",
    "predictions = clf.predict(X)\n",
    "# print(predictions)\n",
    "\n",
    "# accuracy_score(y, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
